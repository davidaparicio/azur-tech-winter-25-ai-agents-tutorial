{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aee3330",
   "metadata": {},
   "source": "# ReAct Agents in LangGraph: Weather + Calendar\n\nObjectives of this notebook:\n\n- Build a **ReAct agent** using two tools: `weather` and `calendar`.\n- Build **the same behavior** with **LangGraph** (but explicit workflow this time).\n- Compare both approaches on several user queries.\n- Observability with Langfuse (local)"
  },
  {
   "cell_type": "markdown",
   "id": "38b6b129",
   "metadata": {},
   "source": "## 0. Graph Setup\n\nWe use:\n- a local LLM via **Ollama** or **LM Studio** (configured in `.env`)\n- two **simulated** tools (no external API):\n  - `fake_get_weather`: simple weather\n  - `fake_calendar_query`: simulated agenda slots"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e95f102",
   "metadata": {},
   "outputs": [],
   "source": "from typing import TypedDict, Optional, List, Literal\nfrom datetime import datetime\n\nimport os\nfrom dotenv import load_dotenv\n\nfrom langchain_core.tools import tool\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain.agents import create_react_agent, AgentExecutor\n\nfrom langgraph.graph import StateGraph, END\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Local LLM configuration\nllm_type = os.getenv(\"LOCAL_LLM_TYPE\", \"ollama\")\n\nif llm_type == \"ollama\":\n    from langchain_ollama import ChatOllama\n    \n    ollama_base_url = os.getenv(\"OLLAMA_BASE_URL\", \"http://localhost:11434\")\n    ollama_model = os.getenv(\"OLLAMA_MODEL\", \"llama3.2:latest\")\n    \n    llm = ChatOllama(\n        model=ollama_model,\n        base_url=ollama_base_url,\n        temperature=0,\n    )\n    print(f\"Using Ollama with model {ollama_model}\")\n    \nelif llm_type == \"lmstudio\":\n    from langchain_openai import ChatOpenAI\n    \n    lmstudio_base_url = os.getenv(\"LMSTUDIO_BASE_URL\", \"http://localhost:1234/v1\")\n    lmstudio_model = os.getenv(\"LMSTUDIO_MODEL\", \"local-model\")\n    \n    llm = ChatOpenAI(\n        model=lmstudio_model,\n        base_url=lmstudio_base_url,\n        api_key=\"not-needed\",  # LM Studio doesn't require an API key\n        temperature=0,\n    )\n    print(f\"Using LM Studio with model {lmstudio_model}\")\n    \nelse:\n    raise ValueError(f\"Unrecognized LOCAL_LLM_TYPE: {llm_type}. Use 'ollama' or 'lmstudio'.\")\n\n# Optional Langfuse configuration for observability\n# If you have configured LANGFUSE_PUBLIC_KEY and LANGFUSE_SECRET_KEY in your .env,\n# observability will be automatically enabled\nif os.getenv(\"LANGFUSE_PUBLIC_KEY\") and os.getenv(\"LANGFUSE_SECRET_KEY\"):\n    try:\n        from langfuse.callback import CallbackHandler\n        \n        langfuse_handler = CallbackHandler(\n            public_key=os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n            secret_key=os.getenv(\"LANGFUSE_SECRET_KEY\"),\n            host=os.getenv(\"LANGFUSE_BASE_URL\", \"http://localhost:3000\")\n        )\n        print(f\"Langfuse enabled on {os.getenv('LANGFUSE_BASE_URL', 'http://localhost:3000')}\")\n    except ImportError:\n        print(\"Langfuse not installed. To enable it: pip install langfuse\")\n        langfuse_handler = None\nelse:\n    langfuse_handler = None\n    print(\"Langfuse not configured (optional)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a776522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated weather tool\n",
    "def fake_get_weather(period: str) -> str:\n",
    "    \"\"\"Simulates a weather API for 'morning', 'afternoon', 'evening' or 'day'.\"\"\"\n",
    "    if period == \"morning\" or period == \"matin\":\n",
    "        return \"This morning: 4°C, feels like 0°C, overcast sky.\"\n",
    "    elif period == \"afternoon\" or period == \"apres-midi\":\n",
    "        return \"This afternoon: 16°C, rain starting at 3pm.\"\n",
    "    elif period == \"evening\" or period == \"soir\":\n",
    "        return \"This evening: 9°C, thunderstorms.\"\n",
    "    else:\n",
    "        return \"Today: between 4°C and 16°C, with some clear skies.\"\n",
    "\n",
    "# Simulated calendar: available slots for Julie\n",
    "FAKE_SLOTS = [\n",
    "    {\"day\": \"thursday\", \"slot\": \"2pm-3pm\", \"person\": \"julie\"},\n",
    "    {\"day\": \"thursday\", \"slot\": \"4pm-5pm\", \"person\": \"gabriel\"},\n",
    "    {\"day\": \"friday\", \"slot\": \"10am-11am\", \"person\": \"julie\"},\n",
    "]\n",
    "\n",
    "def fake_calendar_query(person: str , day: Optional[str] = None) -> str:\n",
    "    \"\"\"Returns simulated slots for a given person.\"\"\"\n",
    "    slots = [s for s in FAKE_SLOTS if s[\"person\"].lower() == person.lower()]\n",
    "    if day:\n",
    "        slots = [s for s in slots if s[\"day\"].lower() == day.lower()]\n",
    "    if not slots:\n",
    "        return f\"No slots available for {person}.\"\n",
    "    return f\"Available slots for {person}: \" + \", \".join(\n",
    "        f\"{s['day']} {s['slot']}\" for s in slots\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1c5580",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERIES = [\n",
    "    \"I want to know the weather for this afternoon.\",\n",
    "    \"Can you suggest a slot with Julie this week?\",\n",
    "    \"If it's nice weather Thursday afternoon, suggest me a slot with Julie.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce21bf21",
   "metadata": {},
   "source": [
    "## 1. ReAct Agent (practical black box)\n",
    "\n",
    "We create a LangChain ReAct agent with two tools:\n",
    "\n",
    "- `weather_tool(period: str)` → calls `fake_get_weather`\n",
    "- `calendar_tool(person: str, day: Optional[str])` → calls `fake_calendar_query`\n",
    "\n",
    "The framework drives the **Thought → Action → Observation** loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4253ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool\n",
    "def weather_tool(period: str) -> str:\n",
    "    \"\"\"Gives simulated weather for 'morning', 'afternoon', 'evening' or 'day'.\"\"\"\n",
    "    return fake_get_weather(period)\n",
    "\n",
    "@tool\n",
    "def calendar_tool(person: str = \"Julie\", day: Optional[str] = None) -> str:\n",
    "    \"\"\"Returns simulated slots for a person (default Julie).\"\"\"\n",
    "    return fake_calendar_query(person=person, day=day)\n",
    "\n",
    "tools = [weather_tool, calendar_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28e82c7",
   "metadata": {},
   "outputs": [],
   "source": "# Using LangChain's standard ReAct prompt\n# This prompt is designed to work correctly with the ReAct parser\ntry:\n    from langchain import hub\n    # Retrieving the standard ReAct prompt from LangChain Hub\n    prompt = hub.pull(\"hwchase17/react\")\nexcept Exception:\n    # If hub.pull doesn't work, we use a custom prompt with the exact ReAct format\n    from langchain_core.prompts import PromptTemplate\n    template = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n\n{tools}\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [{tool_names}]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n\nBegin!\n\nQuestion: {input}\nThought:{agent_scratchpad}\"\"\"\n    prompt = PromptTemplate.from_template(template)\n\nreact_agent = create_react_agent(llm, tools, prompt)\n\n# Configure AgentExecutor with Langfuse if available\nexecutor_config = {\n    \"agent\": react_agent,\n    \"tools\": tools,\n    \"verbose\": True,\n    \"handle_parsing_errors\": True\n}\n\n# Add Langfuse callback if configured\nif langfuse_handler:\n    executor_config[\"callbacks\"] = [langfuse_handler]\n\nreact_executor = AgentExecutor(**executor_config)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b002db95",
   "metadata": {},
   "outputs": [],
   "source": "print(\"### ReAct Agent Demo (black box) ###\")\nfor q in QUERIES:\n    print(f\"\\n=== Question: {q}\")\n    # Prepare configuration with Langfuse callbacks if available\n    invoke_config = {\"input\": q}\n    if langfuse_handler:\n        invoke_config[\"callbacks\"] = [langfuse_handler]\n    \n    result = react_executor.invoke(invoke_config)\n    print(\"Final answer (ReAct):\", result[\"output\"])"
  },
  {
   "cell_type": "markdown",
   "id": "d92a0925",
   "metadata": {},
   "source": [
    "## 4. LangGraph Agent (explicit workflow)\n",
    "\n",
    "We rebuild the **same behavior** with LangGraph:\n",
    "\n",
    "1. Interpret the request (intent + parameters)\n",
    "2. Decide which tools to call (weather, calendar, both)\n",
    "3. Call the tools\n",
    "4. Compose the final answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2146b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IntentType = Literal[\"weather\", \"calendar\", \"both\", \"none\"]\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    user_input: str\n",
    "    intent: IntentType\n",
    "    period: Optional[str]\n",
    "    person: Optional[str]\n",
    "    day: Optional[str]\n",
    "    weather_result: Optional[str]\n",
    "    calendar_result: Optional[str]\n",
    "    final_answer: Optional[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42f7ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def interpret_request(state: AgentState) -> AgentState:\n",
    "    \"\"\"Uses the LLM to classify the request and extract some parameters.\"\"\"\n",
    "    user_input = state[\"user_input\"]\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"You analyze the user request and return a JSON.\n",
    "\n",
    "Request: {user_input}\n",
    "\n",
    "Respond ONLY with a JSON of the form:\n",
    "{{\n",
    "  \"intent\": \"weather\" | \"calendar\" | \"both\" | \"none\",\n",
    "  \"period\": \"morning\" | \"afternoon\" | \"evening\" | \"day\" | null,\n",
    "  \"person\": string or null,\n",
    "  \"day\": string or null\n",
    "}}\n",
    "\"\"\"\n",
    "    )\n",
    "    messages = prompt.format_messages(user_input=user_input)\n",
    "    raw = llm.invoke(messages).content\n",
    "    import json\n",
    "    try:\n",
    "        parsed = json.loads(raw)\n",
    "    except json.JSONDecodeError:\n",
    "        parsed = {\"intent\": \"none\", \"period\": None, \"person\": None, \"day\": None}\n",
    "\n",
    "    state[\"intent\"] = parsed.get(\"intent\", \"none\")\n",
    "    state[\"period\"] = parsed.get(\"period\")\n",
    "    state[\"person\"] = parsed.get(\"person\")\n",
    "    state[\"day\"] = parsed.get(\"day\")\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bc38e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def call_weather_node(state: AgentState) -> AgentState:\n",
    "    period = state.get(\"period\") or \"day\"\n",
    "    state[\"weather_result\"] = fake_get_weather(period)\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77099455",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def call_calendar_node(state: AgentState) -> AgentState:\n",
    "    person = state.get(\"person\")\n",
    "    day = state.get(\"day\")\n",
    "    state[\"calendar_result\"] = fake_calendar_query(person=person, day=day)\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b66c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List\n",
    "\n",
    "def build_final_answer(state: AgentState) -> AgentState:\n",
    "    parts: List[str] = []\n",
    "    if state.get(\"weather_result\"):\n",
    "        parts.append(state[\"weather_result\"])\n",
    "    if state.get(\"calendar_result\"):\n",
    "        parts.append(state[\"calendar_result\"])\n",
    "    if not parts:\n",
    "        parts.append(\"I'm not sure I understand your request.\")\n",
    "\n",
    "    state[\"final_answer\"] = \" \".join(parts)\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb40d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"interpret\", interpret_request)\n",
    "graph.add_node(\"weather\", call_weather_node)\n",
    "graph.add_node(\"calendar\", call_calendar_node)\n",
    "graph.add_node(\"final\", build_final_answer)\n",
    "\n",
    "graph.set_entry_point(\"interpret\")\n",
    "\n",
    "def route_from_intent(state: AgentState):\n",
    "    intent = state.get(\"intent\", \"none\")\n",
    "    if intent == \"weather\":\n",
    "        return \"weather\"\n",
    "    if intent == \"calendar\":\n",
    "        return \"calendar\"\n",
    "    if intent == \"both\":\n",
    "        return \"weather\"\n",
    "    return \"final\"\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"interpret\",\n",
    "    route_from_intent,\n",
    "    {\n",
    "        \"weather\": \"weather\",\n",
    "        \"calendar\": \"calendar\",\n",
    "        \"both\": \"weather\",\n",
    "        \"final\": \"final\",\n",
    "    },\n",
    ")\n",
    "\n",
    "def after_weather(state: AgentState):\n",
    "    if state.get(\"intent\") == \"both\":\n",
    "        return \"calendar\"\n",
    "    return \"final\"\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"weather\",\n",
    "    after_weather,\n",
    "    {\n",
    "        \"calendar\": \"calendar\",\n",
    "        \"final\": \"final\",\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.add_edge(\"calendar\", \"final\")\n",
    "graph.add_edge(\"final\", END)\n",
    "\n",
    "app = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = app.get_graph()\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(g.draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03b6872",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"### LangGraph Agent Demo (explicit workflow) ###\")\n",
    "for q in QUERIES:\n",
    "    print(f\"\\n=== Question: {q}\")\n",
    "    initial_state: AgentState = {\n",
    "        \"user_input\": q,\n",
    "        \"intent\": \"none\",\n",
    "        \"period\": None,\n",
    "        \"person\": None,\n",
    "        \"day\": None,\n",
    "        \"weather_result\": None,\n",
    "        \"calendar_result\": None,\n",
    "        \"final_answer\": None,\n",
    "    }\n",
    "    result = app.invoke(initial_state)\n",
    "    print(\"Final answer (LangGraph):\", result[\"final_answer\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928cde6",
   "metadata": {},
   "source": "## 5. Quick Comparison: ReAct vs LangGraph\n\nOn this small example:\n\n- **ReAct**:\n  - We provide tools and a ReAct prompt.\n  - The framework drives the Thought → Action → Observation loop.\n  - The workflow remains implicit (we guess it via logs or Langfuse).\n\n- **LangGraph**:\n  - We explicitly define the steps (interpret, weather, calendar, answer).\n  - We control transitions (e.g., `intent == \"both\"` → weather then calendar).\n  - The same agent becomes testable, observable, modifiable node by node.\n\nIn production, we can then:\n- Add safeguards,\n- Limit certain tools to certain paths,\n- Connect Langfuse to track costs, latency and errors by node."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}